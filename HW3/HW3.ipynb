{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transform\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Subset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setSeed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfm = transform.Compose([\n",
    "    transform.Resize((128, 128)),\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_tfm = transform.Compose([\n",
    "    transform.RandomRotation(40),\n",
    "    transform.RandomAffine(degrees=0, translate=(0.2, 0.2), shear=0.2),\n",
    "    transform.RandomHorizontalFlip(p=0.5),\n",
    "    transform.Resize((128, 128)),\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class foodDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, tfm=test_tfm):\n",
    "        super(foodDataset).__init__()\n",
    "        self.path = path\n",
    "        self.tfm = tfm\n",
    "        self.imgName = sorted([name for name in os.listdir(self.path) if name.endswith('.jpg')])\n",
    "        self.imgPath = [os.path.join(self.path, name) for name in self.imgName]\n",
    "     \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.imgPath[idx])\n",
    "        img = self.tfm(img)\n",
    "        try:\n",
    "            label = int(self.imgName[idx].split('_')[0])\n",
    "        except:\n",
    "            label = -1\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnnBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, input_chann, output_channel, kernel_size=3, stride=1, padding=1):\n",
    "        super(cnnBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(input_chann, output_channel, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(output_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(linearBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class foodClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, cnnLayers, linearLayers):\n",
    "        super(foodClassifier, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            *[cnnBlock(cnnLayers[i-1], cnnLayers[i]) for i in range(1, len(cnnLayers))]\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            *[linearBlock(linearLayers[i-1], linearLayers[i]) for i in range(1, len(linearLayers))]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoDataset(Dataset):\n",
    "\n",
    "    def __init__(self, unlabeled_set, indices, pseudo_labels):\n",
    "        self.data = Subset(unlabeled_set, indices)\n",
    "        self.target = torch.LongTensor(pseudo_labels)[indices]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if index < 0:\n",
    "            index += len(self)\n",
    "        if index > len(self):\n",
    "            raise IndexError(\"index %d is out of bounds for axis 0 with size %d\"%(index, len(self)))\n",
    "        \n",
    "        x = self.data[index][0]\n",
    "        y = self.target[index].item()\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pseudo_dataset(unlabeled_dataset, model, config, threshhold=0.65):\n",
    "\n",
    "    print('get pseudo labels ... ')\n",
    "    masks = []\n",
    "    pseudo_labels = []\n",
    "    model.eval()\n",
    "\n",
    "    data_loader = DataLoader(unlabeled_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    for batch in tqdm(data_loader):\n",
    "        img, _ = batch\n",
    "        img = img.to(config['device'])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(img)\n",
    "            pred = torch.softmax(pred, dim=1).cpu()\n",
    "\n",
    "        index = torch.argmax(pred, dim=1)\n",
    "        giveup = torch.max(pred, dim=1)[0] > threshhold\n",
    "        pseudo_labels.append(index)\n",
    "        masks.append(giveup)\n",
    "    \n",
    "    pseudo_labels = torch.cat(pseudo_labels, dim=0)\n",
    "    masks = torch.cat(masks, dim=0)\n",
    "    indices = torch.arange(0, len(unlabeled_dataset))[masks]\n",
    "    pseudo = PseudoDataset(unlabeled_dataset, indices, pseudo_labels)\n",
    "    print(f'use {len(indices)/len(unlabeled_dataset):.2f} unlabeled data')\n",
    "\n",
    "    return pseudo            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Trainer(model, train_set, valid_set, config, unlabeled_set=None):\n",
    "    model.to(config['device'])\n",
    "    train_loader = DataLoader(train_set, batch_size=config['batch_size'], shuffle=True)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=config['batch_size'])\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config['step_size'], gamma=config['gamma'])\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    best_acc = 0\n",
    "    step = 0\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    for epoch in range(config['epochNum']):\n",
    "\n",
    "        if config['semi-supervise']:\n",
    "            pseudoDataset = get_pseudo_dataset(unlabeled_set, model, config, threshhold=0.85)\n",
    "            train_set = ConcatDataset((pseudoDataset, train_set))\n",
    "            train_loader = DataLoader(train_set, batch_size=config['batch_size'], shuffle=True)\n",
    "            print(\"total number of training data: \", len(train_set))\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        train_loss, train_acc = 0.0, 0.0\n",
    "\n",
    "        for data in tqdm(train_loader):\n",
    "            img, label = data\n",
    "            img, label = img.to(config['device']), label.to(config['device'])\n",
    "\n",
    "            pred = model(img)\n",
    "            loss = criterion(pred, label)\n",
    "\n",
    "            # clear gradients in every batch\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_acc += (pred.argmax(dim=-1) == label).float().mean()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_acc / len(train_loader)\n",
    "        writer.add_scalar(config['writerName'] + 'Loss/Train', train_loss, epoch)\n",
    "        writer.add_scalar(config['writerName'] + 'Accuracy/Train', train_acc, epoch)\n",
    "\n",
    "        model.eval()\n",
    "        valid_acc, valid_loss = 0.0, 0.0\n",
    "        for data in tqdm(valid_loader):\n",
    "            img, label = data \n",
    "            img, label = img.to(config['device']), label.to(config['device'])\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                pred = model(img)\n",
    "\n",
    "            loss = criterion(pred, label)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            valid_acc += (pred.argmax(dim=-1) == label).float().mean()\n",
    "\n",
    "        valid_acc, valid_loss = valid_acc / len(valid_loader), valid_loss / len(valid_loader)\n",
    "        writer.add_scalar(config['writerName'] + 'Loss/Valid', valid_loss, epoch)\n",
    "        writer.add_scalar(config['writerName'] + 'Accuracy/Valid', valid_acc, epoch)\n",
    "        print(f'epoch[{epoch}] | train loss: {train_loss:.5f} train acc: {train_acc:.4f} | valid loss: {valid_loss:.5f} valid acc: {valid_acc:.4f}')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(config['modelSavePath'], config['lastModel']))\n",
    "        if best_acc < valid_acc:\n",
    "            best_acc = valid_acc\n",
    "            torch.save(model.state_dict(), os.path.join(config['modelSavePath'], config['bestModel']))\n",
    "            print(f'find A better model! acc: {best_acc:.4f}')\n",
    "            step = 0\n",
    "        else:\n",
    "            step += 1\n",
    "            if step > config['early_stop']:\n",
    "                print('Cannot improve model~')\n",
    "                break\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'learning_rate': 1e-3,\n",
    "    'batch_size': 64,\n",
    "    'cnnLayers': [3, 64, 128, 256, 512],\n",
    "    'linearLayers': [512*8*8, 1024, 512, 256, 11],\n",
    "    'gamma': 0.8,\n",
    "    'step_size': 10,\n",
    "    'weight_decay': 1e-3,\n",
    "    'seed': 914122,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'epochNum': 400,\n",
    "    'early_stop': 50,\n",
    "    'modelSavePath': './model/',\n",
    "    'bestModel': 'best_0915.ckpt',\n",
    "    'lastModel': 'last_0915.ckpt',\n",
    "    'trainImgPath': './data/training/',\n",
    "    'validImgPath': './data/validation/',\n",
    "    'testImgPath': './data/test/',\n",
    "    'writerName': 'HW3 ',\n",
    "    'unlabelPath': './data/test',\n",
    "    'semi-supervise': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(config['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = foodDataset(config['trainImgPath'], tfm=train_tfm)\n",
    "valid_set = foodDataset(config['validImgPath'])\n",
    "test_set = foodDataset(config['testImgPath'])\n",
    "unlabel_set = foodDataset(config['unlabelPath'], tfm=train_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_set, batch_size=config['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = foodClassifier(config['cnnLayers'], config['linearLayers'])\n",
    "# model.load_state_dict(torch.load('./model/last_0915.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get pseudo labels ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use 0.00 unlabeled data\n",
      "total number of training data:  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0] | train loss: 2.77232 train acc: 0.1212 | valid loss: 2.39610 valid acc: 0.1333\n",
      "find A better model! acc: 0.1333\n",
      "get pseudo labels ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use 0.00 unlabeled data\n",
      "total number of training data:  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Trainer(model, train_set, valid_set, config, unlabeled_set\u001b[39m=\u001b[39;49munlabel_set)\n",
      "\u001b[1;32m/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb Cell 24\u001b[0m in \u001b[0;36mTrainer\u001b[0;34m(model, train_set, valid_set, config, unlabeled_set)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb#X26sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m img, label \u001b[39m=\u001b[39m data\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb#X26sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m img, label \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mto(config[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m]), label\u001b[39m.\u001b[39mto(config[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m pred \u001b[39m=\u001b[39m model(img)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(pred, label)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# clear gradients in every batch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb Cell 24\u001b[0m in \u001b[0;36mfoodClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mflatten(start_dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(x)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb Cell 24\u001b[0m in \u001b[0;36mcnnBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/weightwater/feu/NTULearn/HW3/HW3.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock(x)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Trainer(model, train_set, valid_set, config, unlabeled_set=unlabel_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
